{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9de6ebc",
   "metadata": {
    "id": "3c03e925-515f-40d0-88ae-a279b42e1077"
   },
   "source": [
    "## Text Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c499ef53",
   "metadata": {
    "id": "Jep8ct1CMge9"
   },
   "source": [
    "### Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb55776e",
   "metadata": {
    "id": "72f8d91c-5290-43fa-bcaf-33a53a870b12"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import itertools\n",
    "import spacy\n",
    "from nltk import FreqDist, bigrams\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from pyvis.network import Network\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "sns.set(rc={'figure.figsize':(15,7)})\n",
    "\n",
    "\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c196b7be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How did humanity come to accept rectangular pieces of pulped trees as something to spend eight to ten hours a day working for? It's a pretty insane story. This change from hard currency like gold or silver is a really huge deal. Without it, we couldn't possibly have the massive industrial and post-industrial economies we know today. This change revolutionized how we do business and forever altered how governments were financed. Learning about this massive sea change in how we as a species thought about money can help us reflect on our current historical shift from seeing paper as money, to seeing bits, seeing digital ones and zeros as money. But before we can get the exciting story of people trying to convince other people that paper was worth something, to understand why this is such a huge deal, we have to discuss a bit about how we thought about money before paper. If we go way back to the beginning of society, we find trade. Before early humans even really settled down, there's evidence that, when we met, we exchanged things we had made or things we'd found. But as soon as humans started to cultivate the earth and form societies, we started to specialize and that meant that we not only loved to trade, we had to. Now, often when we think of trade we think of long distance trade. We think of caravans loaded with exotic goods. But for our story, we have to talk about local trade. Because here's where we run into the problem of Coincidence of Wants. Or rather, we run into it everywhere. But if we fail to solve this problem at the local level, society breaks down and we can't have the specialised trades we need to run anything beyond the smallest gathering of people. So what is a Coincidence of Wants? It's the basis on which trade can exist. Let's say that I make shirts, and you grow food. Well, if you want a shirt and I want food, awesome, we can trade. But if I don't want\n",
      "your stupid food, or if you're all full up on shirts, well, we can't trade, can we? And that\n",
      "starts becoming a real problem for society if i want food but you don't\n",
      "want my shirts. Maybe I can find somebody with some third good that you do want.\n",
      "But that means that a lot of time is consumed by trading. And if I can't find\n",
      "some other good you want to trade for, well, there's gonna be trouble. And this\n",
      "problem runs even deeper than we sometimes think about when you consider the lack of\n",
      "refrigeration and transportation. Imagine I'm a fisherman and you're a farmer, and\n",
      "let's say that we want to trade. Well there's this problem; your harvest\n",
      "only comes in once a year. I can't trade you for a harvest you don't have yet, and\n",
      "all of those extra fish I caught today are going to be pretty rotten by the\n",
      "time your harvest comes in. And while this may seem like a very specific\n",
      "example, trade for food was probably the most prevalent trade of the ancient world.\n",
      "So we need to find a third good that we both want that we can trade for. But\n",
      "wouldn't it be convenient if there was some universal third good which\n",
      "everybody wanted and would trade for? So we didn't have to do some long chain of bartering every time we wanted something. Enter, money. All money is is a third good\n",
      "that doesn't spoil and that we all agree has value, thus becoming a unit of\n",
      "exchange; An intermediary good, by which all other goods can be traded. And while we often think of coins made\n",
      "of precious metals for this purpose, the truth is, so long as it's durable enough\n",
      "and hard enough to procure, anything can serve as money. Tangent time: Turns out\n",
      "we have used a lot of weird stuff as money over our history. For example,\n",
      "cattle have often served as money. I mean, they're fairly durable, they last for\n",
      "years, they're practical, and they're reasonably\n",
      "scarce. When Europeans arrived in the Americas, alcohol often served as\n",
      "currency. You could literally drink your paycheck. Cigarettes have often become\n",
      "money of prisons and POW camps. Back in ancient China, money in the shape of tools and then knives became some of the first examples of precious metal money.\n",
      "And, my personal favorite, on the island of Yap, gigantic limestone donuts serve\n",
      "as money. They are so huge that once they are brought to the island, no one even moves them. They just remember who owns which ones. In fact, all of these stones had to be quarried off-island,\n",
      "because there's no naturally-occurring limestone on Yap. And once when a crew was coming back\n",
      "from a quarrying expedition, a storm hit and sent their stone to the bottom of the\n",
      "ocean. But the crew survived and told everybody what had happened, and the\n",
      "Islanders decided that \"Eh, it still counted.\" So to this day, somebody owns\n",
      "that giant piece of stone money at the bottom of the sea. And even though it's\n",
      "not really in use today, for hundreds of years that stone was used to buy and\n",
      "sell things, even though no one had ever seen it, giving Yap, in some ways, one of the most forward-thinking monetary systems before the modern era. But if we\n",
      "want to talk about the king of them all, the form of money that has been used the\n",
      "longest and over the widest expanse of the globe, we have to talk about one\n",
      "thing. No, not gold. Although in fairness, that's\n",
      "what I would have guessed too. Nope, it's the cowry shell. It's durable, impossible\n",
      "to counterfeit, and without modern harvesting techniques it's not so easy\n",
      "to acquire that inflation will run rampant. Anyway, tangent over, back on\n",
      "target. We have lots of different possible types\n",
      "of pre-modern money, including the gold and silver coins that we so often think\n",
      "of when we think of money of the past. But all of these different types of\n",
      "money have one thing in common: they are what we call commodity money, because\n",
      "their value is in the commodity themselves. Even cowries were seen as\n",
      "rare and beautiful, and can be used for jewelry and the like, and so were thought\n",
      "of as having intrinsic value. The same way we feel gold has an intrinsic value\n",
      "for its scarcity and its uses. Now, that makes a lot of sense for a\n",
      "currency. It feels secure and reasonable. You can trust to the worth of that gold\n",
      "coin in your hand. I mean, after all, if you're used to\n",
      "trading one thing for another, why would you ever trade something\n",
      "valuable like a horse for something worthless like a pile of paper? But for\n",
      "gold or for cowries, well that's another story. But when your economy\n",
      "grows, this system starts showing some of its limits. For one thing, commodity money is heavy. If you're doing massive deals, it gets\n",
      "really hard to transport. And it's risky to transport across lawless lands.\n",
      "Commodity money is also often subject to debasing, where somebody. usually the\n",
      "person who should be responsible for making sure the currency maintains its\n",
      "value, waters down the whiskey, or takes a gold coin, melts it down, and reforges it\n",
      "with a bit less gold in it, and passes it off as worth the same amount. But more\n",
      "than anything, when you get to gigantic economies, the very scarcity that makes\n",
      "commodity money seem to have value becomes your enemy. Like, let's take gold\n",
      "and silver. What happens when your economy grows to the point where you\n",
      "just can't get enough of it? We actually saw the effects of this in\n",
      "our episode on the Opium Wars, where so much English silver was ending up in\n",
      "China in exchange for tea, it was actually causing inflation, and\n",
      "hampering basic economic transactions at home. And this really comes into effect\n",
      "when we get to more modern government finance, and the financing of war. What happens to a nation when it has to\n",
      "make a sudden drastic uptick in its spending, but can't get enough specie to\n",
      "cover its cost? Even from those who are willing to lend? As I am sure we will see\n",
      "in future Extra History episodes, it plays havoc with an economy, and even the ability to prosecute a war. And the reverse of this is true as well. Currencies based on scarcity are often\n",
      "subject to changes in the scarcity of the commodity on which they're based, which can be trouble when somebody finds a lot more of your currency commodity. When\n",
      "Spain started to important massive amounts of silver and gold from the\n",
      "Americas, all the precious metal-based currency in Europe started to suffer\n",
      "from inflation. After all, all those gold coins weren't worth nearly as much since\n",
      "somebody had just dumped a huge new pile of gold on European shores. And as a\n",
      "government, or even a financial sector, when someone digging up a new pile of\n",
      "minerals means that you can't control your own fiscal policy, then that's bad\n",
      "news. But those disadvantages are only easy to see if you're a head of state or\n",
      "working on the largest-scale transactions. If you're just some average\n",
      "person in the street, when some well-to-do says that they want to take\n",
      "your grain in exchange for this nice slip of... is that paper? Well, you would be forgiven for thinking\n",
      "that you smell a rat. Join us next time as we finally delve into the origins of\n",
      "paper money, and start to address this problem of people fearing to give up\n",
      "their outdated gold.  1633\n"
     ]
    }
   ],
   "source": [
    "def generate_transcript(id):\n",
    "\ttranscript = YouTubeTranscriptApi.get_transcript(id,languages=['en'])\n",
    "\tscript = \"\"\n",
    "\n",
    "\tfor text in transcript:\n",
    "\t\tt = text[\"text\"]\n",
    "\t\tif t != '[Music]':\n",
    "\t\t\tscript += t + \" \"\n",
    "\t\t\n",
    "\treturn script, len(script.split())\n",
    "\n",
    "iden = '-nZkP2b-4vo'\n",
    "\n",
    "#ID é a parte final do link, depois do \"=\", exemplo \n",
    "#https://www.youtube.com/watch?v=L_jWHffIx5E\n",
    "#L_jWHffIx5E\n",
    "\n",
    "transcript, no_of_words = generate_transcript(iden)\n",
    "print(transcript,no_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c557cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript2 = YouTubeTranscriptApi.get_transcript(iden,languages=['en'])\n",
    "\n",
    "# dicionário do momento de cada fala\n",
    "legend_dict = {}\n",
    "for text in transcript2:\n",
    "    legend_dict[text['start']] = text['text']\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "504e71ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = KeyedVectors.load_word2vec_format(\"./../../wiki-news-300d-1M.vec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8220d39",
   "metadata": {
    "id": "79b33fc5-b0fa-4a13-a7d3-b8f4687ce013"
   },
   "source": [
    "### Auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6258adc",
   "metadata": {
    "id": "e2a3ac55-0cdb-45c2-b26a-882bf8243355",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "toktok = ToktokTokenizer()\n",
    "stpwrd = stopwords.words('english')\n",
    "stop_list = (['uh', 'also', 'oh', 'um', 'yeah', 'use', 'lot', 'put', 'get', 'would', 'gonna', 'really', 'much', 'actually', 'another'])\n",
    "stpwrd.extend(stop_list)\n",
    "\n",
    "'''for word in stpwrd:\n",
    "    print(word)\n",
    "    '''\n",
    "    \n",
    "    \n",
    "#Acha as N palavras mais similares a string passada e retorna uma lista com as palavras. (Sem a métrica de proximidade)\n",
    "def getSimilar(string, N):\n",
    "    similarList = modelo.most_similar(positive=[string])[0:N]\n",
    "    wordList = []\n",
    "    for word in similarList:\n",
    "        wordList.append(word)\n",
    "    return wordList\n",
    "\n",
    "def sort_list(list1, list2):\n",
    "     \n",
    "    list3 = []\n",
    "    for entry in list2:\n",
    "        list3.append(entry[1])\n",
    "    zipped_pairs = zip(list3, list1)\n",
    " \n",
    "    z = [x for _, x in sorted(zipped_pairs, reverse = True)]\n",
    " \n",
    "    return z\n",
    "\n",
    "\n",
    "\n",
    "#Busca na label dos nós por palavras similares a stopwords\n",
    "def banStopword(lista):\n",
    "    SUSwords = []\n",
    "    similarWords = []\n",
    "    for word in lista:\n",
    "        similares = getSimilar(word,5)\n",
    "        mostSimilar = 0\n",
    "        similarWord = ''\n",
    "        SUSWord = ''\n",
    "        for palavra in similares:\n",
    "            sentinel = 0\n",
    "            if palavra[0] in stpwrd and palavra[1] > mostSimilar:\n",
    "                mostSimilar = palavra[1]\n",
    "                similarWord = palavra\n",
    "                SUSWord = word\n",
    "                sentinel = 1\n",
    "                print(mostSimilar, similarWord, SUSWord)\n",
    "            if sentinel == 1:  \n",
    "                SUSwords.append(word)\n",
    "                similarWords.append(palavra)\n",
    "\n",
    "    return SUSwords, similarWords\n",
    "\n",
    "'''word_tokens = toktok.tokenize(example_sent)\n",
    "\n",
    "filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]\n",
    "\n",
    "filtered_sentence = []\n",
    "\n",
    "for w in word_tokens:\n",
    "\tif w not in stop_words:\n",
    "\t\tfiltered_sentence.append(w)\n",
    "\n",
    "print(word_tokens)\n",
    "print(filtered_sentence)'''\n",
    "\n",
    "\n",
    "def filtered_sentence(example_sent):\n",
    "    word_tokens = toktok.tokenize(example_sent)\n",
    "    filtered_sentence = [w for w in word_tokens if not w.lower() in stpwrd]\n",
    "    return \" \".join(filtered_sentence)\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    doc = filtered_sentence(text)\n",
    "    print(\" \".join([token.text for token in doc if token.is_stop == False]))\n",
    "    return \" \".join([token.text for token in doc if token.is_stop == False])\n",
    "\n",
    "def pre_processing(text):\n",
    "    text = filtered_sentence(text)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text) #remove punctuation\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "    return text\n",
    "\n",
    "def co_occurrence(text):\n",
    "    corpus = list(itertools.chain.from_iterable([text.split(' ')]))\n",
    "    vocab = list(set(corpus))\n",
    "    vocab_index = {word: i for i, word in enumerate(vocab)}\n",
    "    bi_grams = list(bigrams(corpus))\n",
    "    bigram_freq = FreqDist(bi_grams).most_common(len(bi_grams)) \n",
    "    co_occurrence_matrix = np.zeros((len(vocab), len(vocab))) \n",
    "    \n",
    "    #bigram = ((word n, word n+1), num_occurrences)\n",
    "    for bigram in bigram_freq:\n",
    "        current = bigram[0][1] #word n+1\n",
    "        previous = bigram[0][0] #word n\n",
    "        count = bigram[1] #num_occurrences\n",
    "        pos_current = vocab_index[current] #obtain id for word n+1 \n",
    "        pos_previous = vocab_index[previous] #obtain id for word n \n",
    "        co_occurrence_matrix[pos_current][pos_previous] = count\n",
    "        \n",
    "    return co_occurrence_matrix, vocab_index\n",
    "\n",
    "def structure_text_network(matrix, vocab_index):\n",
    "    data_matrix = pd.DataFrame(matrix, index=vocab_index, columns=vocab_index)\n",
    "    data_stack = data_matrix.stack()\n",
    "    structure = data_stack[data_stack >= 1].rename_axis(('source', 'target')).reset_index(name='weight')\n",
    "    return structure[(structure.source != \" \") & (structure.target != \" \")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9a2347e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7335886359214783 ('another', 0.7335886359214783) one\n",
      "0.6885168552398682 ('how', 0.6885168552398682) what\n",
      "0.7364087700843811 ('a', 0.7364087700843811) another\n"
     ]
    }
   ],
   "source": [
    "lista = ['one', 'measurements', 'what', 'also', 'me', 'mice', 'five', 'standard', 'stat', 'imagine', 'spread', 'weighed', 'look', 'mean', 'another', 'quest', 'quantifies', 'often', 'let', 'plot', 'set', 'deviation', 'data', 'measured', 'differences']\n",
    "\n",
    "lista1, lista2 = banStopword(lista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b162de9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['one', 'what', 'another']\n",
      "\n",
      " [('another', 0.7335886359214783), ('how', 0.6885168552398682), ('a', 0.7364087700843811)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['another', 'one', 'what']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(lista1)\n",
    "print('\\n',lista2)\n",
    "sort_list(lista1, lista2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02459771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('another', 0.7335886359214783),\n",
       " ('only', 0.7045549750328064),\n",
       " ('each', 0.6934645771980286),\n",
       " ('a', 0.6761848330497742),\n",
       " ('either', 0.6739281415939331)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getSimilar('one',5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85b7b02",
   "metadata": {
    "id": "cb6013f9-167e-48c2-bf33-ae21fb5db4a0"
   },
   "source": [
    "### Generate text network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dda8a170",
   "metadata": {
    "id": "3cec1db4-75f9-422b-90c3-11b671df00af"
   },
   "outputs": [],
   "source": [
    "from spacy.lang.pt.stop_words import STOP_WORDS\n",
    "nlp = spacy.load(\"pt_core_news_sm\")\n",
    "#STOP_WORDS.add('gotta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "618ecd2d",
   "metadata": {
    "id": "c2cb690f-54b3-4d08-88c3-e527938e6129"
   },
   "outputs": [],
   "source": [
    "text = transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e780b462",
   "metadata": {
    "id": "8be9e201-f14c-4d98-ade0-a5d12c28d544"
   },
   "outputs": [],
   "source": [
    "text_cleaned = pre_processing(text)\n",
    "matrix, vocab = co_occurrence(text_cleaned)\n",
    "structure_network = structure_text_network(matrix, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a36953c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "t1S3k5jk06Lj",
    "outputId": "a88fb51a-b6c2-40ab-e80c-0da77a035ac2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cowries</td>\n",
       "      <td>Even</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cowries</td>\n",
       "      <td>gold</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>target</td>\n",
       "      <td>back</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hampering</td>\n",
       "      <td>inflation</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>worthless</td>\n",
       "      <td>something</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>still</td>\n",
       "      <td>Eh</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>Yap</td>\n",
       "      <td>island</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>Yap</td>\n",
       "      <td>limestone</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>Yap</td>\n",
       "      <td>giving</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>enemy</td>\n",
       "      <td>becomes</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>738 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        source     target  weight\n",
       "0      cowries       Even     1.0\n",
       "1      cowries       gold     1.0\n",
       "2       target       back     1.0\n",
       "3    hampering  inflation     1.0\n",
       "4    worthless  something     1.0\n",
       "..         ...        ...     ...\n",
       "733      still         Eh     1.0\n",
       "734        Yap     island     1.0\n",
       "735        Yap  limestone     1.0\n",
       "736        Yap     giving     1.0\n",
       "737      enemy    becomes     1.0\n",
       "\n",
       "[738 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structure_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84e7e373",
   "metadata": {
    "id": "7b5a7e92-018a-45a6-a32b-555a9550928f"
   },
   "outputs": [],
   "source": [
    "text_network = nx.DiGraph()\n",
    "text_network = nx.from_pandas_edgelist(structure_network, 'target', 'source', ['weight'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fb528b",
   "metadata": {
    "id": "5156a3b0-1833-4d01-9dbd-d591265f7c37"
   },
   "source": [
    "### PageRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0eba0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_network = nx.DiGraph()\n",
    "text_network = nx.from_pandas_edgelist(structure_network, 'target', 'source', ['weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "578b9822",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pagerank_centrality(G):\n",
    "    centrality =  nx.pagerank(G)\n",
    "    return sorted(centrality.items(), key=lambda x: x[1], reverse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c8bd518",
   "metadata": {},
   "outputs": [],
   "source": [
    "centrality = pagerank_centrality(text_network)\n",
    "\n",
    "#dicionário da centralidade\n",
    "cen_dict = {}\n",
    "max_cen = 0\n",
    "for x in centrality:\n",
    "    cen_dict[x[0]] = x[1]\n",
    "    if max_cen < x[1]:\n",
    "        max_cen = x[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f72b7d",
   "metadata": {
    "id": "bb3ce1d1-5cba-4c64-9dcc-9b4bc1d7a432"
   },
   "source": [
    "### Graph Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7bc0c410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lista dos nós\n",
    "name_lst = [x[0] for x in centrality]\n",
    "\n",
    "# lista de nós a serem removidos, estamos mantendo os 25 maiores\n",
    "rmv_lst = name_lst[:-25]\n",
    "\n",
    "# exibição do nome dos nós para a visualização\n",
    "for i in text_network.nodes:\n",
    "    text_network.nodes[i]['label'] = i\n",
    "\n",
    "# redução do grafo mantendo a conectividade\n",
    "for i in rmv_lst:\n",
    "    maxi = 0\n",
    "    for j in text_network.neighbors(i):\n",
    "        w = name_lst.index(j)\n",
    "        if maxi < w:\n",
    "            maxi = w\n",
    "            merge_node = j\n",
    "            \n",
    "    for j in text_network.neighbors(i):\n",
    "        if not (j == merge_node or (j in text_network.neighbors(merge_node))):\n",
    "            text_network.add_edge(merge_node, j, weight=text_network[i][j]['weight']/2)\n",
    "    text_network.remove_node(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f412eaef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gold was appended at 0.0\n",
      "something was appended at 0.0\n",
      "one was appended at 0.0\n",
      "money was appended at 0.0\n",
      "used was appended at 0.0\n",
      "often was appended at 0.0\n",
      "problem was appended at 0.0\n",
      "time was appended at 0.0\n",
      "value was appended at 0.0\n",
      "currency was appended at 0.0\n",
      "started was appended at 0.0\n",
      "trade was appended at 0.0\n",
      "worth was appended at 0.0\n",
      "think was appended at 0.0\n",
      "commodity was appended at 0.0\n",
      "paper was appended at 0.0\n",
      "people was appended at 0.0\n",
      "enough was appended at 0.0\n",
      "massive was appended at 0.0\n",
      "even was appended at 0.0\n",
      "run was appended at 0.0\n",
      "want was appended at 0.0\n",
      "like was appended at 0.0\n",
      "somebody was appended at 0.0\n",
      "good was appended at 0.0\n",
      "money was appended at 49.62\n",
      "paper was appended at 49.62\n",
      "trade was appended at 55.92\n",
      "even was appended at 57.02\n",
      "started was appended at 64.9\n",
      "often was appended at 73.44\n",
      "think was appended at 73.44\n",
      "problem was appended at 82.3\n",
      "run was appended at 82.3\n",
      "people was appended at 95.08\n",
      "trade was appended at 100.04\n",
      "want was appended at 105.76\n",
      "somebody was appended at 116.399\n",
      "time was appended at 120.93\n",
      "good was appended at 120.93\n",
      "problem was appended at 128.729\n",
      "even was appended at 128.729\n",
      "think was appended at 132.72\n",
      "trade was appended at 153.18\n",
      "like was appended at 153.18\n",
      "want was appended at 162.03\n",
      "good was appended at 165.959\n",
      "something was appended at 170.34\n",
      "time was appended at 170.34\n",
      "money was appended at 173.849\n",
      "value was appended at 179.94\n",
      "often was appended at 186.42\n",
      "think was appended at 186.42\n",
      "enough was appended at 190.2\n",
      "used was appended at 194.4\n",
      "currency was appended at 209.34\n",
      "money was appended at 218.069\n",
      "one was appended at 233.22\n",
      "even was appended at 233.22\n",
      "somebody was appended at 254.31\n",
      "used was appended at 262.89\n",
      "want was appended at 271.27\n",
      "money was appended at 274.99\n",
      "one was appended at 279.07\n",
      "gold was appended at 281.77\n",
      "run was appended at 290.47\n",
      "often was appended at 300.76\n",
      "think was appended at 300.76\n",
      "value was appended at 307.9\n",
      "commodity was appended at 307.9\n",
      "used was appended at 311.5\n",
      "even was appended at 311.5\n",
      "like was appended at 315.55\n",
      "currency was appended at 323.17\n",
      "gold was appended at 327.07\n",
      "worth was appended at 327.07\n",
      "one was appended at 330.34\n",
      "something was appended at 333.34\n",
      "trade was appended at 333.34\n",
      "paper was appended at 336.52\n",
      "money was appended at 344.74\n",
      "massive was appended at 347.83\n",
      "often was appended at 351.43\n",
      "commodity was appended at 351.43\n",
      "somebody was appended at 355.9\n",
      "value was appended at 359.5\n",
      "gold was appended at 376.51\n",
      "like was appended at 376.51\n",
      "enough was appended at 380.71\n",
      "even was appended at 404.02\n",
      "often was appended at 418.6\n",
      "commodity was appended at 422.44\n",
      "somebody was appended at 422.44\n",
      "currency was appended at 426.1\n",
      "started was appended at 426.1\n",
      "massive was appended at 426.1\n",
      "gold was appended at 429.79\n",
      "worth was appended at 437.38\n",
      "want was appended at 461.08\n",
      "paper was appended at 464.38\n",
      "time was appended at 466.69\n",
      "money was appended at 470.26\n",
      "gold was appended at 474.31\n",
      "problem was appended at 474.31\n",
      "people was appended at 474.31\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 54, 99, 152, 332]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# momentos em que cada palavra é dita\n",
    "dict_moments = {}\n",
    "episilon = 45\n",
    "\n",
    "for i in text_network.nodes:\n",
    "    dict_moments[i] = []\n",
    "    \n",
    "for i in list(legend_dict.keys()):\n",
    "    phrase = pre_processing(legend_dict[i]).lower()\n",
    "    \n",
    "    for j in text_network.nodes:\n",
    "        if len(dict_moments[j]) == 0 or (j in phrase.split() and dict_moments[j][-1]+episilon<i):\n",
    "            dict_moments[j].append((i>1)*(int(i)-1))\n",
    "            print(f\"{j} was appended at {i}\")\n",
    "    \n",
    "dict_moments['trade']        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd5ec8fa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local cdn resources have problems on chrome/safari when used in jupyter-notebook. \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1000px\"\n",
       "            height=\"600px\"\n",
       "            src=\"text_network.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f473ad95c00>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nt = Network('800px', '1000px', notebook=True)\n",
    "nt.from_nx(text_network)\n",
    "for edg in nt.edges:\n",
    "    # espessura e física das arestas\n",
    "    #edg['width'] = text_network[i][j]['weight']**4\n",
    "    #if edg['weight'] < 1:\n",
    "    \n",
    "    if edg['from'] == edg['to']:\n",
    "        edg['hidden'] = True\n",
    "    edg['physics'] = False\n",
    "\n",
    "for n in nt.nodes:\n",
    "    # tamanho dos nós\n",
    "    n['shape'] = 'ellipse'\n",
    "    size = 30*(cen_dict[n['label']]/max_cen)**0.4\n",
    "    n['font'] = str(int(size))+'px arial white'\n",
    "    n['color'] = '#7f333f'\n",
    "    n['labelHighlightBold'] = True\n",
    "    \n",
    "\n",
    "def time_to_min(time):\n",
    "    return str(time//60)+\":\"+\"0\"*(time%60<10)+str(time%60)\n",
    "\n",
    "for n in nt.nodes:\n",
    "    # links nos nós\n",
    "    link_list = [\"<a href='https://www.youtube.com/watch?v=\"+str(iden)+\n",
    "                 \"&t=\"+str(time)+\"s' target='_blank' rel='noopener noreferrer'>\"+time_to_min(time)+\"<br>\" for time in dict_moments[n['label']]]\n",
    "    soma = ''\n",
    "    for k in link_list:\n",
    "        soma += k\n",
    "    n['title'] = soma\n",
    "    #print(n['size'])\n",
    "\n",
    "    \n",
    "nt.show(\"text_network.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e16ec1ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gold', 'paper', 'like', 'worth', 'money', 'value', 'people', 'want', 'trade', 'massive', 'often', 'even', 'commodity', 'enough', 'currency', 'think', 'something', 'one', 'used', 'time', 'problem', 'run', 'started', 'good', 'somebody']\n"
     ]
    }
   ],
   "source": [
    "#print(nx.adjacency_matrix(text_network))\n",
    "#print(nt.nodes)\n",
    "lista = []\n",
    "for node in nt.nodes:\n",
    "    lista.append(node['label'])\n",
    "print(lista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "00693a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6788149476051331 ('too', 0.6788149476051331) enough\n",
      "0.7335886359214783 ('another', 0.7335886359214783) one\n",
      "(['enough', 'one'], [('too', 0.6788149476051331), ('another', 0.7335886359214783)])\n"
     ]
    }
   ],
   "source": [
    "SUS = banStopword(lista)\n",
    "print(SUS)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
