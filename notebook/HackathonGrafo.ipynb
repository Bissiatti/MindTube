{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3c03e925-515f-40d0-88ae-a279b42e1077"
   },
   "source": [
    "## Text Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jep8ct1CMge9"
   },
   "source": [
    "### Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "72f8d91c-5290-43fa-bcaf-33a53a870b12"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import itertools\n",
    "import spacy\n",
    "from nltk import FreqDist, bigrams\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from pyvis.network import Network\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "sns.set(rc={'figure.figsize':(15,7)})\n",
    "\n",
    "\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi I’m John Green and this is Crash Course\n",
      "European History. So we’re going to turn our attention now\n",
      "to the Industrial Revolution, one of the most significant developments in human history. Like, imagine with me that it’s 1820. I got this idea from the economist Robert\n",
      "Gordon by the way. You live in, say, England. You probably work in agriculture. When you walk to town, you’re either pulling\n",
      "your own cart, or if you’re lucky you have a horse. You have no running water or electricity. When you wash your few items of clothing,\n",
      "you do so by hand. You cook over a fire. You think of time not primarily in minutes\n",
      "and hours, but mostly in relationship to solar cycles--how close it is to night, or to morning,\n",
      "or to midwinter. And in all these respects, your life in 1820\n",
      "is basically identical to the lives of people in 1720, or 1520, or for that matter 1220. That’s not to say life hasn’t changed\n",
      "in those hundreds of years--as we’ve explored in this series, lots has changed--but as Gregory\n",
      "Clark observed, in terms of standard of living, Europeans in 1800 basically led lives similar\n",
      "to those of Neandrathals. Now imagine that you close your eyes in 1820\n",
      "and wake up in 1920. By now, most people in England do not work\n",
      "in agriculture. They may work in shops, or transportation,\n",
      "or mining, oe workshops, or in factories. They measure time in minutes. Cars exist. Some people have radios, which transmitted\n",
      "information through thin air. A few people even have refrigerators, which\n",
      "dramatically decrease food spoilage and the risk of foodborne illness. Occasionally you might even see an airplane\n",
      "flying in the sky. Oh, and also, your country has just emerged\n",
      "from an astonishingly deadly war fought with highly lethal weapons such as chlorine gas,\n",
      "weapons that people of 1820 could not possibly have imagined. Welcome to the Industrial Revolution. [Intro]\n",
      "In this series, we’ve already talked about revolutions in agriculture that increased\n",
      "European productivity and revolutions in trade that increasingly distributed goods among\n",
      "people in towns and cities instead of having each individual family produce everything\n",
      "it needed. And these forces combined to help create more\n",
      "division of labor: like, farmers could focus on farming, and textile workers could focus\n",
      "on textile creation, which was more efficient than having each family do every kind of work. So let’s begin in the eighteenth century,\n",
      "when European industrial production is said to have begun. Europe’s population was growing after centuries\n",
      "of non-stop wars, plagues, and the worst of the little ice age. Meanwhile, products such as coffee, tea, and\n",
      "chocolate made with heated water killed bacteria, while products from abroad expanded and varied\n",
      "the pool of nutrients, with corn and potatoes, for instance, generally more calorie-dense\n",
      "per acre than wheat. In short, lives were getting longer and populations\n",
      "rising. This meant that on average people had a little\n",
      "more time to learn, tinker, and experiment. Many different artisans invented small improvements\n",
      "to existing mechanical devices. Perhaps most famously, John Kay’s flying\n",
      "shuttle increased the pace and productivity of weaving. Weavers then needed a greater amount of thread. So tinkerers made that happen by producing\n",
      "inventions such as the spinning jenny, created around 1764 by craftsman James Hargreaves. The spinning jenny was a machine used by individual\n",
      "women working at home. And it allowed a person, using just the power\n",
      "of their hand, to spin not one bobbin of thread, but up to 120 at once. In England, Ellen Hacking and her husband\n",
      "John were among those devising carding machines to straighten cotton and wool fibers for spinning. And at about the same time, Richard Arkwright\n",
      "and his partners invented the water frame, another kind of spinning machine that used\n",
      "water power. And when spinning machines could be linked\n",
      "to a central power source such as water, many could be placed in a single building. So, the world’s first factories arose in\n",
      "part from the pressure to increase production of English cloth for global and domestic markets. Did the center of the world just open? Is one of my Polo shirts in there? This cost like $41. Twice a year I go to a Polo outlet in Southern\n",
      "Indiana and just buy as many of these things as they’ll sell to me. And look, I’m not here to advertise Polo\n",
      "shirts, but this thing is incredibly comfortable, and also, it’s like dyed a specific color. Everything about this was completely unimaginable\n",
      "in the early nineteenth century. In fact, you know what? It’s so soft to the touch, I think I’m\n",
      "going to put it on. Is that weird. Oh yeah! I feel like I’m the bad guy in an 80s movie. How do I look, Stan? Oh, Stan says I look like Steve Bannon. OK. Thus ends that experiment, now back to the\n",
      "show. Let’s talk about porcelain. Another tinkerer was the alchemist Johann\n",
      "Friedrich Böttger who promised the king of Saxony that he could figure out how to make\n",
      "porcelain. Porcelain was such an obsession that wealthy\n",
      "people collected it and even those with far less would try to buy a piece or two—a cup\n",
      "or plate—as we see in many Dutch, French, and other paintings. Two things you see a lot in European paintings\n",
      "of the affluent or those who aspired to affluence: porcelain and pineapples, which were also\n",
      "quite rare and expensive and difficult to produce domestically. Porcelain was also practical, because Europeans\n",
      "did not know other ways to make heat resistant dishware for their hot drinks. So Böttger was virtually imprisoned until\n",
      "around 1708 when he figured out how to make porcelain, although not as beautifully as\n",
      "the Chinese or Japanese did. What we’re trying to get at here is that\n",
      "while people love a great story of an inventor and their invention, the Industrial Revolution\n",
      "was the story of lots and lots of people working together, making a series of incremental improvements,\n",
      "rather than, like, geniuses from on high creating amazing things. The real genius of humans is collaboration,\n",
      "and also spying. Like for instance, Industrial spies helped\n",
      "with every development because other regions were far more advanced than Europe in manufacturing,\n",
      "for instance, color fast dyes and heat-resistant dishware, fine weaving and spinning, or even\n",
      "metallurgy. Arkwright, for example, mostly copied designs\n",
      "from imported textiles. And it was those cotton textiles that caught\n",
      "the imagination of consumers and filled pockets, first of the people who imported textiles\n",
      "from India and China, and then of the daring manufacturers who were successful at copying\n",
      "the lightweight, and colorful, and washable cotton clothing. But industrial production of cotton was really\n",
      "risky—the rate of business failure during the Industrial Revolution was over 50 percent. Because of that, experimenting manufacturers\n",
      "worked to keep labor costs as low as they could. One way was to use unpaid orphans from government,\n",
      "religious or charitable institutions as labour. At a time when people didn’t know a lot\n",
      "about steam powered machinery and its dangers, industrial accidents happened all the time,\n",
      "and children were often the victims. Children worked incredibly long hours and\n",
      "deaths were common. Little Mary Richards was caught up in a machine\n",
      "and six- and seven- year old orphans working alongside her witnessed the quote “bones\n",
      "of her arms, legs, thighs, etc successively snap... her head appeared dashed to pieces...\n",
      "her blood thrown about like water from a twirled mop.”2\n",
      "Now I know that’s very graphic, but I think it’s important to understand the extent\n",
      "of industrial oppression, including the industrial oppression of children. Workers lost arms, eyes, breasts, and fingers\n",
      "or were otherwise disfigured. Production and profits came first to avoid\n",
      "financial ruin. And industry had other repercussions. It initially increased the demand for slaves\n",
      "even more. Slaves produced food for workers who had left\n",
      "farms for factories. Slaves also produced tropical crops such as\n",
      "sugar, and tobacco, and coffee that boosted the energy of many types of workers. And slaves provided the palm and other tropical\n",
      "oils to keep machinery running as well as the raw materials for industry, especially\n",
      "cotton. It’s important to understand that industry\n",
      "thrived due to slave labor and inexpensive child labor, and also through the labor of\n",
      "women, who were paid less than men. Over time, more and more people began working\n",
      "in industrialized settings, or in economic sectors that supported industry due in part\n",
      "to the development of the steam engine. In 1776, English inventor James Watt launched\n",
      "a steam engine that improved earlier models. Now as far back as Roman Egypt and then Ottoman\n",
      "Egypt and China, people had known about steam engines, But Watt’s engine was more efficient,\n",
      "which made it useful in replacing animal and water power, not just in mines but also powering\n",
      "textile factories, and then other machinery. For millennia, almost all human power came\n",
      "from our muscles. Then we harnessed some animal power, and eventually\n",
      "some wind and water power. But steam power completely revolutionized\n",
      "how much work could be done on behalf of humans, and also of course changed transportation\n",
      "when it was attached to covered and uncovered wagons and ships to make trains and steamships\n",
      "and eventually automobiles. And the train created another kind of demand:\n",
      "as urbanization soared around railway hubs, small and grand train stations were built\n",
      "along with all the other buildings to house the railway’s primary and secondary employees. By secondary employees I mean, it wasn’t\n",
      "just station-masters, ticket-sellers, and conductors, there was a need for shopkeepers,\n",
      "and pharmacists, and construction workers, and teachers, and doctors, and and drivers\n",
      "of coaches, not to mention sanitation workers, police, and urban administrators. Industrialization had a snowball effect and\n",
      "it wasn’t gonna be turned back. And all this mean that everyday life also\n",
      "transformed. Two classes became prominent alongside the\n",
      "aristocracy and peasants in the social structure: the bourgeoisie and proletariat or working\n",
      "class. The bourgeoisie initially referred to people\n",
      "who lived in towns and cities or burgs/bourgs. But the term came to refer to those who owned\n",
      "factories, banks, transportation networks, and large tracts of land for raising livestock\n",
      "and crops. The proletariat comprise the many factory\n",
      "and other workers who lacked tools or land to support themselves but instead rather labored\n",
      "for factory owners and others who had the means to produce. In between were the rising professional groups,\n",
      "called the middle class in Europe: the doctors, lawyers, teachers, and others with special\n",
      "skills that serviced society as a whole. We will see this configuration change over\n",
      "the next two centuries and watch tensions unfold among these groups, and at times boil\n",
      "over. Women also experienced a transformation of\n",
      "everyday life. In the preceding centuries, they had generally\n",
      "worked on farms or in workshops alongside their artisan husbands or on their own as\n",
      "hatmakers, and seamstresses, and weavers, and spinners. During the early days of industrialization,\n",
      "women who had been spinning or weaving at home often switched to factories. And they did many other kinds of work; for\n",
      "example, eighteen-year-old Ann Eggly with her younger sister worked twelve-hour days\n",
      "in the coal mines pushing carriages filled with 800 pounds of coal (which was then used\n",
      "to make steam power). She had done this kind of work since she was\n",
      "seven. I don’t know if you know any seven year\n",
      "olds, but they should not be working in coal mines. Now you’ll recall that the French and American\n",
      "revolutions, with their emphasis on motherhood and laws stripping women of their property,\n",
      "led to women being discouraged from work. But many continued to do so even when their\n",
      "wages belonged to their husbands. Factories also created (and still create)\n",
      "outwork done by women at home: polishing knives or painting porcelain buttons for example. But, ideology simultaneously shifted to say\n",
      "that women were to be “angels in the household,” providing comfort from the horrors of industrial\n",
      "life, a cultural norm that discouraged work outside the home. In the meantime, the classes became aware\n",
      "of their individual identities. The French had outlawed guilds during the\n",
      "revolution. Industrial and other workers formed their\n",
      "own clubs to protect their interests. They created singing, gymnastic, and sports\n",
      "clubs--this is why early English football teams had names like Royal Engineers AFC and\n",
      "Civil Service FC. These groups often had a lively cafe culture,\n",
      "where they discussed politics and read newspapers, often allowed to their comrades because each\n",
      "cafe usually only had one newspaper. Manufacturers and wealthy individuals in cities\n",
      "likewise formed groups based on their common class position; they founded chambers of commerce\n",
      "to protect their financial interests and museums to show off their city’s achievements and\n",
      "good taste. Let’s go to the Thought Bubble. 1. Initially, the rise of factories saw those\n",
      "left out of industrial work life, 2. such as artisans and small farmers, 3. protest by breaking machinery or threatening\n",
      "to do so. 4. The “Swing riots” in Britain are one example\n",
      "of what has been called “primitive” rebellion. 5. Instead of dealing with change by organizing\n",
      "to benefit from and shape the change, 6. so-called primitive rebels went about breaking\n",
      "things. 7. Wreckers of machinery were called Luddites 8. (as they still are today) 9. because menacing notes found alongside\n",
      "sabotage were often signed Ned Ludd. 10. Ludd was an inspirational figure -- a weaver\n",
      "who allegedly smashed a textile machine in the 18th century. 11. But gradually, workers inside the factories\n",
      "formed mutual aid societies 12. and eventually unions that negotiated\n",
      "for better terms with owners. And when negotiations failed, 13. they went on strike as a group instead of\n",
      "wrecking the machines with which they earned their living. 14. All in all, industrialization wreaked havoc\n",
      "on people’s lives even as it provided many with livelihoods. 15. Towns grew astronomically: like textile center\n",
      "Manchester England went from 20,000 people in the 1750s to 400,000 a century later. 16. Conditions in Manchester were abominable,\n",
      "including the development of slums, and the spread of disease. 17. They came to lack fresh and safe supplies\n",
      "of water. 18. Garbage and sewage, not to mention animal\n",
      "excrement, filled muddy streets, 19. creating, in the words of one commentator,\n",
      "“a universal atmosphere of filth and stink.”[1] 20. and Conditions in other industrial cities\n",
      "hardly differed. Thanks Thought Bubble. So, Industrialization spread from England\n",
      "and the low countries where it began thanks to the capital raised by worldwide trade,\n",
      "and because that trade made possible successful imitation of foreign products. But industrialization then spread. It traveled the continent through the 19th\n",
      "century, although industrialization was less dense in eastern Europe. There, many peasants continued to live hand-to-mouth,\n",
      "but as we’ve seen, so did the poor in industrial cities. So was the Industrial Revolution a revolution? Well, if a revolution is an event full of\n",
      "impact on people’s lives, it certainly was. But often historians look at revolutions as,\n",
      "like, ending, which the Industrial Revolution really hasn’t. Unlike the comparatively brief English Revolution\n",
      "or American Revolution, many see the Industrial Revolution as continuing to make dramatic\n",
      "changes in our way of life today. Today, we expect technologies to change dramatically\n",
      "in our lifetimes. We expect to use different tools to communicate\n",
      "and work than our parents used. But that expectation is only a couple hundred\n",
      "years old. It makes you wonder. If you closed your eyes in 2020, and woke\n",
      "up in 2120, how weird is the world gonna be. Ugh. Thinking about that is stressing me out.Next\n",
      "time, we’ll look further at the cultural and political aspects of industrialization. I’ll see you then. Thanks for watching. ________________\n",
      "[1] Quoted in Lynn Hunt et al., The Making of the West: Peoples and Cultures, 6th ed. (Boston: Bedford St. Martin’s, 2019) 21.  2619\n"
     ]
    }
   ],
   "source": [
    "def generate_transcript(id):\n",
    "\ttranscript = YouTubeTranscriptApi.get_transcript(id,languages=['en'])\n",
    "\tscript = \"\"\n",
    "\n",
    "\tfor text in transcript:\n",
    "\t\tt = text[\"text\"]\n",
    "\t\tif t != '[Music]':\n",
    "\t\t\tscript += t + \" \"\n",
    "\t\t\n",
    "\treturn script, len(script.split())\n",
    "\n",
    "iden = 'zjK7PWmRRyg'\n",
    "\n",
    "#ID é a parte final do link, depois do \"=\", exemplo \n",
    "#https://www.youtube.com/watch?v=L_jWHffIx5E\n",
    "#L_jWHffIx5E\n",
    "\n",
    "transcript, no_of_words = generate_transcript(iden)\n",
    "print(transcript,no_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript2 = YouTubeTranscriptApi.get_transcript(iden,languages=['en'])\n",
    "\n",
    "# dicionário do momento de cada fala\n",
    "legend_dict = {}\n",
    "for text in transcript2:\n",
    "    legend_dict[text['start']] = text['text']\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-54592791ab72>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodelo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKeyedVectors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"C:/Users/rafae/Downloads/MindTube-main (2)/MindTube-main/notebook/wiki-news-300d-1M.vec\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mload_word2vec_format\u001b[1;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header)\u001b[0m\n\u001b[0;32m   1721\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1722\u001b[0m         \"\"\"\n\u001b[1;32m-> 1723\u001b[1;33m         return _load_word2vec_format(\n\u001b[0m\u001b[0;32m   1724\u001b[0m             \u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfvocab\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfvocab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbinary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0municode_errors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0municode_errors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1725\u001b[0m             \u001b[0mlimit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatatype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdatatype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mno_header\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mno_header\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36m_load_word2vec_format\u001b[1;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header, binary_chunk_size)\u001b[0m\n\u001b[0;32m   2071\u001b[0m             )\n\u001b[0;32m   2072\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2073\u001b[1;33m             \u001b[0m_word2vec_read_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcounts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvector_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatatype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0municode_errors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2074\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mkv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2075\u001b[0m         logger.info(\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36m_word2vec_read_text\u001b[1;34m(fin, kv, counts, vocab_size, vector_size, datatype, unicode_errors, encoding)\u001b[0m\n\u001b[0;32m   1973\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_word2vec_read_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcounts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvector_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatatype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0municode_errors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1974\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mline_no\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1975\u001b[1;33m         \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1976\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mline\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34mb''\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1977\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"unexpected end of input; is count incorrect or file otherwise damaged?\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "modelo = KeyedVectors.load_word2vec_format(\"C:/Users/rafae/Downloads/MindTube-main (2)/MindTube-main/notebook/wiki-news-300d-1M.vec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "79b33fc5-b0fa-4a13-a7d3-b8f4687ce013"
   },
   "source": [
    "### Auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "id": "e2a3ac55-0cdb-45c2-b26a-882bf8243355",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "toktok = ToktokTokenizer()\n",
    "stpwrd = stopwords.words('english')\n",
    "stop_list = (['uh', 'also', 'oh', 'um', 'yeah', 'use', 'lot', 'put', 'get', 'would', 'gonna', 'really', 'much', 'actually', 'another'])\n",
    "stpwrd.extend(stop_list)\n",
    "\n",
    "'''for word in stpwrd:\n",
    "    print(word)\n",
    "    '''\n",
    "    \n",
    "    \n",
    "#Acha as N palavras mais similares a string passada e retorna uma lista com as palavras. (Sem a métrica de proximidade)\n",
    "def getSimilar(string, N):\n",
    "    similarList = modelo.most_similar(positive=[string])[0:N]\n",
    "    wordList = []\n",
    "    for word in similarList:\n",
    "        wordList.append(word)\n",
    "    return wordList\n",
    "\n",
    "def sort_list(list1, list2):\n",
    "     \n",
    "    list3 = []\n",
    "    for entry in list2:\n",
    "        list3.append(entry[1])\n",
    "    zipped_pairs = zip(list3, list1)\n",
    " \n",
    "    z = [x for _, x in sorted(zipped_pairs, reverse = True)]\n",
    " \n",
    "    return z\n",
    "\n",
    "\n",
    "\n",
    "#Busca na label dos nós por palavras similares a stopwords\n",
    "def banStopword(lista):\n",
    "    SUSwords = []\n",
    "    similarWords = []\n",
    "    for word in lista:\n",
    "        similares = getSimilar(word,5)\n",
    "        mostSimilar = 0\n",
    "        similarWord = ''\n",
    "        SUSWord = ''\n",
    "        for palavra in similares:\n",
    "            sentinel = 0\n",
    "            if palavra[0] in stpwrd and palavra[1] > mostSimilar:\n",
    "                mostSimilar = palavra[1]\n",
    "                similarWord = palavra\n",
    "                SUSWord = word\n",
    "                sentinel = 1\n",
    "                print(mostSimilar, similarWord, SUSWord)\n",
    "            if sentinel == 1:  \n",
    "                SUSwords.append(word)\n",
    "                similarWords.append(palavra)\n",
    "\n",
    "    return SUSwords, similarWords\n",
    "\n",
    "'''word_tokens = toktok.tokenize(example_sent)\n",
    "\n",
    "filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]\n",
    "\n",
    "filtered_sentence = []\n",
    "\n",
    "for w in word_tokens:\n",
    "\tif w not in stop_words:\n",
    "\t\tfiltered_sentence.append(w)\n",
    "\n",
    "print(word_tokens)\n",
    "print(filtered_sentence)'''\n",
    "\n",
    "\n",
    "def filtered_sentence(example_sent):\n",
    "    word_tokens = toktok.tokenize(example_sent)\n",
    "    filtered_sentence = [w for w in word_tokens if not w.lower() in stpwrd]\n",
    "    return \" \".join(filtered_sentence)\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    doc = filtered_sentence(text)\n",
    "    print(\" \".join([token.text for token in doc if token.is_stop == False]))\n",
    "    return \" \".join([token.text for token in doc if token.is_stop == False])\n",
    "\n",
    "def pre_processing(text):\n",
    "    text = filtered_sentence(text)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text) #remove punctuation\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "    return text\n",
    "\n",
    "def co_occurrence(text):\n",
    "    corpus = list(itertools.chain.from_iterable([text.split(' ')]))\n",
    "    vocab = list(set(corpus))\n",
    "    vocab_index = {word: i for i, word in enumerate(vocab)}\n",
    "    bi_grams = list(bigrams(corpus))\n",
    "    bigram_freq = FreqDist(bi_grams).most_common(len(bi_grams)) \n",
    "    co_occurrence_matrix = np.zeros((len(vocab), len(vocab))) \n",
    "    \n",
    "    #bigram = ((word n, word n+1), num_occurrences)\n",
    "    for bigram in bigram_freq:\n",
    "        current = bigram[0][1] #word n+1\n",
    "        previous = bigram[0][0] #word n\n",
    "        count = bigram[1] #num_occurrences\n",
    "        pos_current = vocab_index[current] #obtain id for word n+1 \n",
    "        pos_previous = vocab_index[previous] #obtain id for word n \n",
    "        co_occurrence_matrix[pos_current][pos_previous] = count\n",
    "        \n",
    "    return co_occurrence_matrix, vocab_index\n",
    "\n",
    "def structure_text_network(matrix, vocab_index):\n",
    "    data_matrix = pd.DataFrame(matrix, index=vocab_index, columns=vocab_index)\n",
    "    data_stack = data_matrix.stack()\n",
    "    structure = data_stack[data_stack >= 1].rename_axis(('source', 'target')).reset_index(name='weight')\n",
    "    return structure[(structure.source != \" \") & (structure.target != \" \")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7335886359214783 ('another', 0.7335886359214783) one\n",
      "0.6885168552398682 ('how', 0.6885168552398682) what\n",
      "0.7364087700843811 ('a', 0.7364087700843811) another\n"
     ]
    }
   ],
   "source": [
    "lista = ['one', 'measurements', 'what', 'also', 'me', 'mice', 'five', 'standard', 'stat', 'imagine', 'spread', 'weighed', 'look', 'mean', 'another', 'quest', 'quantifies', 'often', 'let', 'plot', 'set', 'deviation', 'data', 'measured', 'differences']\n",
    "\n",
    "lista1, lista2 = banStopword(lista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['one', 'what', 'another']\n",
      "\n",
      " [('another', 0.7335886359214783), ('how', 0.6885168552398682), ('a', 0.7364087700843811)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['another', 'one', 'what']"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(lista1)\n",
    "print('\\n',lista2)\n",
    "sort_list(lista1, lista2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('crowning', 0.6477673053741455),\n",
       " ('Grandest', 0.5972409844398499),\n",
       " ('Crowned', 0.5812886953353882),\n",
       " ('Rejoicing', 0.5547146797180176),\n",
       " ('Surmounting', 0.5538868308067322),\n",
       " ('Boldest', 0.5468339323997498),\n",
       " ('Adorned', 0.5416989326477051),\n",
       " ('Symbolizes', 0.5404633283615112),\n",
       " ('Enthronement', 0.5369417071342468),\n",
       " ('Timelessness', 0.5364014506340027)]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getSimilar('Crowning',25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cb6013f9-167e-48c2-bf33-ae21fb5db4a0"
   },
   "source": [
    "### Generate text network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "id": "3cec1db4-75f9-422b-90c3-11b671df00af"
   },
   "outputs": [],
   "source": [
    "from spacy.lang.pt.stop_words import STOP_WORDS\n",
    "nlp = spacy.load(\"pt_core_news_sm\")\n",
    "#STOP_WORDS.add('gotta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "id": "c2cb690f-54b3-4d08-88c3-e527938e6129"
   },
   "outputs": [],
   "source": [
    "text = transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "id": "8be9e201-f14c-4d98-ade0-a5d12c28d544"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Industrial', 'Revolution', 'Crash', 'Course', 'European', 'History', '24']"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_cleaned = pre_processing(text)\n",
    "matrix, vocab = co_occurrence(text_cleaned)\n",
    "structure_network = structure_text_network(matrix, vocab)\n",
    "\n",
    "v_title = \"The Industrial Revolution: Crash Course European History #24\"\n",
    "\n",
    "title_words = pre_processing(v_title).split()\n",
    "title_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "t1S3k5jk06Lj",
    "outputId": "a88fb51a-b6c2-40ab-e80c-0da77a035ac2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>greater</td>\n",
       "      <td>needed</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>machine</td>\n",
       "      <td>caught</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>machine</td>\n",
       "      <td>spinning</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>machine</td>\n",
       "      <td>jenny</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>machine</td>\n",
       "      <td>textile</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1442</th>\n",
       "      <td>still</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1443</th>\n",
       "      <td>still</td>\n",
       "      <td>created</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1444</th>\n",
       "      <td>discouraged</td>\n",
       "      <td>norm</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1445</th>\n",
       "      <td>discouraged</td>\n",
       "      <td>women</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1446</th>\n",
       "      <td>negotiated</td>\n",
       "      <td>unions</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1447 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           source    target  weight\n",
       "0         greater    needed     1.0\n",
       "1         machine    caught     1.0\n",
       "2         machine  spinning     1.0\n",
       "3         machine     jenny     1.0\n",
       "4         machine   textile     1.0\n",
       "...           ...       ...     ...\n",
       "1442        still         8     1.0\n",
       "1443        still   created     1.0\n",
       "1444  discouraged      norm     1.0\n",
       "1445  discouraged     women     1.0\n",
       "1446   negotiated    unions     1.0\n",
       "\n",
       "[1447 rows x 3 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structure_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "id": "7b5a7e92-018a-45a6-a32b-555a9550928f"
   },
   "outputs": [],
   "source": [
    "text_network = nx.DiGraph()\n",
    "text_network = nx.from_pandas_edgelist(structure_network, 'target', 'source', ['weight'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5156a3b0-1833-4d01-9dbd-d591265f7c37"
   },
   "source": [
    "### PageRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_network = nx.DiGraph()\n",
    "text_network = nx.from_pandas_edgelist(structure_network, 'target', 'source', ['weight'])\n",
    "for i in text_network.nodes:\n",
    "    for j in text_network.nodes:\n",
    "        if i != j and i.lower() == j.lower():\n",
    "            text_network = nx.contracted_nodes(text_network,i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pagerank_centrality(G):\n",
    "    centrality =  nx.pagerank(G)\n",
    "    return sorted(centrality.items(), key=lambda x: x[1], reverse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "centrality = pagerank_centrality(text_network)\n",
    "\n",
    "def mean_simi(word,title):\n",
    "    m = 0\n",
    "    for i in title:\n",
    "        try:\n",
    "            m += modelo.similarity(word, i)\n",
    "        except KeyError:\n",
    "            m += 0\n",
    "    return m/len(title)\n",
    "\n",
    "centrality = [(x[0],x[1]*mean_simi(x[0],title_words)) for x in centrality]\n",
    "#dicionário da centralidade\n",
    "cen_dict = {}\n",
    "max_cen = 0\n",
    "for x in centrality:\n",
    "    cen_dict[x[0]] = x[1]\n",
    "    if max_cen < x[1]:\n",
    "        max_cen = x[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bb3ce1d1-5cba-4c64-9dcc-9b4bc1d7a432"
   },
   "source": [
    "### Graph Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lista dos nós\n",
    "name_lst = [x[0] for x in centrality]\n",
    "\n",
    "# lista de nós a serem removidos, estamos mantendo os 25 maiores\n",
    "rmv_lst = name_lst[:-25]\n",
    "\n",
    "# exibição do nome dos nós para a visualização\n",
    "for i in text_network.nodes:\n",
    "    text_network.nodes[i]['label'] = i\n",
    "\n",
    "# redução do grafo mantendo a conectividade\n",
    "for i in rmv_lst:\n",
    "    maxi = 0\n",
    "    for j in text_network.neighbors(i):\n",
    "        w = name_lst.index(j)\n",
    "        if maxi < w:\n",
    "            maxi = w\n",
    "            merge_node = j\n",
    "    text_network.remove_node(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Industrial was appended at 2.759\n",
      "Like was appended at 10.65\n",
      "work was appended at 18.91\n",
      "water was appended at 26.4\n",
      "time was appended at 34.219\n",
      "people was appended at 44.989\n",
      "life was appended at 44.989\n",
      "work was appended at 78.29\n",
      "time was appended at 87.6\n",
      "people was appended at 90.82\n",
      "even was appended at 95.75\n",
      "see was appended at 102.75\n",
      "could was appended at 112.7\n",
      "Industrial was appended at 120.55\n",
      "people was appended at 138.849\n",
      "workers was appended at 152.68\n",
      "work was appended at 158.04\n",
      "century was appended at 161.4\n",
      "water was appended at 174.159\n",
      "people was appended at 194.91\n",
      "time was appended at 194.91\n",
      "Many was appended at 201.219\n",
      "spinning was appended at 215.529\n",
      "working was appended at 223.64\n",
      "women was appended at 223.64\n",
      "power was appended at 228.03\n",
      "water was appended at 244.239\n",
      "time was appended at 244.239\n",
      "could was appended at 251.879\n",
      "century was appended at 285.02\n",
      "porcelain was appended at 301.81\n",
      "make was appended at 307.09\n",
      "could was appended at 307.09\n",
      "people was appended at 310.52\n",
      "even was appended at 310.52\n",
      "see was appended at 314.979\n",
      "porcelain was appended at 347.33\n",
      "people was appended at 355.62\n",
      "working was appended at 355.62\n",
      "Industrial was appended at 355.62\n",
      "Like was appended at 375.83\n",
      "spinning was appended at 387.639\n",
      "even was appended at 387.639\n",
      "people was appended at 401.72\n",
      "Industrial was appended at 417.4\n",
      "could was appended at 426.01\n",
      "One was appended at 427.039\n",
      "time was appended at 433.819\n",
      "machinery was appended at 433.819\n",
      "often was appended at 439.569\n",
      "working was appended at 448.44\n",
      "water was appended at 460.389\n",
      "even was appended at 488.46\n",
      "workers was appended at 493.219\n",
      "machinery was appended at 505.27\n",
      "women was appended at 518.669\n",
      "people was appended at 523.32\n",
      "time was appended at 523.32\n",
      "working was appended at 523.32\n",
      "water was appended at 551.66\n",
      "power was appended at 551.66\n",
      "machinery was appended at 551.66\n",
      "work was appended at 567.69\n",
      "could was appended at 567.69\n",
      "make was appended at 579.11\n",
      "workers was appended at 605.06\n",
      "life was appended at 622.99\n",
      "working was appended at 632.93\n",
      "people was appended at 636.449\n",
      "workers was appended at 653.389\n",
      "see was appended at 676.339\n",
      "life was appended at 685.66\n",
      "spinning was appended at 700.69\n",
      "industrialization was appended at 700.69\n",
      "women was appended at 700.69\n",
      "often was appended at 704.779\n",
      "work was appended at 707.529\n",
      "make was appended at 717.2\n",
      "power was appended at 717.2\n",
      "working was appended at 725.05\n",
      "even was appended at 739.959\n",
      "women was appended at 745.389\n",
      "Factories was appended at 745.389\n",
      "porcelain was appended at 750.589\n",
      "life was appended at 760.44\n",
      "work was appended at 760.44\n",
      "revolution was appended at 772.73\n",
      "workers was appended at 776.269\n",
      "Industrial was appended at 776.269\n",
      "often was appended at 792.07\n",
      "life was appended at 819.3\n",
      "work was appended at 819.3\n",
      "machinery was appended at 825.59\n",
      "often was appended at 845.97\n",
      "century was appended at 856.91\n",
      "workers was appended at 859.02\n",
      "people was appended at 875.279\n",
      "even was appended at 875.279\n",
      "industrialization was appended at 875.279\n",
      "water was appended at 896.92\n",
      "industrialization was appended at 926.49\n",
      "century was appended at 928.62\n",
      "revolution was appended at 941.279\n",
      "Industrial was appended at 941.279\n",
      "people was appended at 944.529\n",
      "often was appended at 950.74\n",
      "see was appended at 958.779\n",
      "life was appended at 964.77\n",
      "make was appended at 964.77\n",
      "work was appended at 974.879\n",
      "time was appended at 992.87\n",
      "industrialization was appended at 995.29\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'trade'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-207-20c2b3187977>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{j} was appended at {i}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mdict_moments\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'trade'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m: 'trade'"
     ]
    }
   ],
   "source": [
    "# momentos em que cada palavra é dita\n",
    "dict_moments = {}\n",
    "episilon = 45\n",
    "\n",
    "for i in text_network.nodes:\n",
    "    dict_moments[i] = []\n",
    "    \n",
    "for i in list(legend_dict.keys()):\n",
    "    phrase = pre_processing(legend_dict[i])\n",
    "    \n",
    "    for j in text_network.nodes:\n",
    "        if j in phrase.split() and (len(dict_moments[j]) == 0 or  dict_moments[j][-1]+episilon<i):\n",
    "            dict_moments[j].append((i>1)*(int(i)-1))\n",
    "            print(f\"{j} was appended at {i}\")\n",
    "    \n",
    "dict_moments['trade']        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1000px\"\n",
       "            height=\"800px\"\n",
       "            src=\"text_network.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x25c1d612790>"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nt = Network('800px', '1000px', bgcolor='#222222', notebook=True)\n",
    "nt.from_nx(text_network)\n",
    "nt.force_atlas_2based(gravity = -200)\n",
    "for edg in nt.edges:\n",
    "    # espessura e física das arestas\n",
    "    #edg['width'] = text_network[i][j]['weight']**4\n",
    "    #if edg['weight'] < 1:\n",
    "    \n",
    "    if edg['from'] == edg['to']:\n",
    "        edg['hidden'] = True\n",
    "    edg['physics'] = True\n",
    "    edg['color'] = '#cf888f'\n",
    "\n",
    "for n in nt.nodes:\n",
    "    # tamanho dos nós\n",
    "    n['shape'] = 'ellipse'\n",
    "    size = 40*(cen_dict[n['label']]/max_cen)**0.4\n",
    "    n['font'] = str(int(size))+'px arial white'\n",
    "    n['color'] = '#7f333f'\n",
    "    n['labelHighlightBold'] = True\n",
    "    \n",
    "\n",
    "def time_to_min(time):\n",
    "    return str(time//60)+\":\"+\"0\"*(time%60<10)+str(time%60)\n",
    "\n",
    "for n in nt.nodes:\n",
    "    # links nos nós\n",
    "    link_list = [\"<a href='https://www.youtube.com/watch?v=\"+str(iden)+\n",
    "                 \"&t=\"+str(time)+\"s' target='_blank' rel='noopener noreferrer'>\"+time_to_min(time)+\"<br>\" for time in dict_moments[n['label']]]\n",
    "    soma = ''\n",
    "    for k in link_list:\n",
    "        soma += k\n",
    "    n['title'] = soma\n",
    "    #print(n['size'])\n",
    "\n",
    "    \n",
    "nt.show(\"text_network.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['spinning', 'power', 'women', 'even', 'time', 'people', 'working', 'life', 'industrial', 'work', 'many', 'factories', 'see', 'water', 'Revolution', 'could', 'one', 'Industrial', 'porcelain', 'make', 'like', 'machinery', 'workers', 'century', 'often']\n"
     ]
    }
   ],
   "source": [
    "#print(nx.adjacency_matrix(text_network))\n",
    "#print(nt.nodes)\n",
    "lista = []\n",
    "for node in nt.nodes:\n",
    "    lista.append(node['label'])\n",
    "print(lista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6883577704429626 ('doing', 0.6883577704429626) working\n",
      "0.7955270409584045 ('most', 0.7955270409584045) many\n",
      "0.6570900082588196 ('get', 0.6570900082588196) see\n",
      "0.8800161480903625 ('can', 0.8800161480903625) could\n",
      "0.7335886359214783 ('another', 0.7335886359214783) one\n",
      "(['working', 'many', 'see', 'could', 'one'], [('doing', 0.6883577704429626), ('most', 0.7955270409584045), ('get', 0.6570900082588196), ('can', 0.8800161480903625), ('another', 0.7335886359214783)])\n"
     ]
    }
   ],
   "source": [
    "SUS = banStopword(lista)\n",
    "print(SUS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
